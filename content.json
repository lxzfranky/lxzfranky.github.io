{"meta":{"title":"Franky's Diary","subtitle":"把有限的生命投入到我开心就好的事情中去","description":null,"author":"lxzfranky","url":"http://www.lxzfranky.com"},"pages":[{"title":"about","date":"2017-09-06T11:03:49.000Z","updated":"2017-09-13T08:32:38.000Z","comments":true,"path":"about/index.html","permalink":"http://www.lxzfranky.com/about/index.html","excerpt":"","text":"正在学习 算法算法算法"}],"posts":[{"title":"树的一些基本概念","slug":"c-tree","date":"2017-09-16T03:22:26.000Z","updated":"2017-09-20T09:05:32.000Z","comments":true,"path":"2017/09/16/c-tree/","link":"","permalink":"http://www.lxzfranky.com/2017/09/16/c-tree/","excerpt":"","text":"写在前面 看了几天，参考了一些帖子整理了下数据结构中的各种树的概念 目录 零、树 一、二叉树 二、平衡二叉树 三、二叉查找树（BST） 四、红黑树 五、完全二叉树（AVL树） 六、满二叉树 七、B树 零、树 树结构的特点是：它的每一个结点都可以有不止一个直接后继，除根结点外的所有结点都有且只有一个直接前趋，是由一个或多个结点组成的有限集合，以下是官方定义。 必有一个特定的称为根(ROOT)的结点 剩下的结点被分成ｎ&gt;=0个互不相交的集合T1、T2、……Tn，而且， 这些集合的每一个又都是树。树T1、T2、……Tn被称作根的子树(Subtree) （1）至少有一个结点（称为根）（2）其它是互不相交的子树 树的宽度，就是结点的分支数。以组成该树各结点中最大的度作为该树的度，树中宽度为零的结点称为叶结点或终端结点。树中度不为零的结点称为分枝结点或非终端结点。除根结点外的分枝结点统称为内部结点。 树的深度是组成该树各结点的最大层次 森林指若干棵互不相交的树的集合 有序树指树中同层结点从左到右有次序排列，它们之间的次序不能互换，这样的树称为有序树，否则称为无序树。 一、二叉树 在计算机科学中，二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）。 二、平衡二叉树 平衡二叉树又被称为AVL树（区别于AVL算法），它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 三、二叉查找树（BST） 别名 二叉排序树 二叉搜索树，具有如下特点 若左子树不空，则左子树上所有结点的值均小于它的根结点的值 若右子树不空，则右子树上所有结点的值均大于它的根结点的值 左、右子树也分别为二叉排序树 没有键值相等的节点（因此，插入的时候一定是叶子节点） 查找效率最好O(logn)，最坏O(n) 插入效率和查找效率相同（只插入叶子节点） 删除效率最好O(logn)+O(1)-&gt;只有左子树或者右子树，最差O(logn)+O(logn)-&gt;左子树和右子树同时存在 插入算法 首先执行查找算法，找出被插结点的父亲结点。 判断被插结点是其父亲结点的左、右儿子。将被插结点作为叶子结点插入。 若二叉树为空。则首先单独生成根结点。 删除算法 若*p结点为叶子结点，即PL(左子树)和PR(右子树)均为空树。由于删去叶子结点不破坏整棵树的结构，则可以直接删除此子结点。 若*p结点只有左子树PL或右子树PR，此时只要令PL或PR直接成为其双亲结点*f的左子树（当*p是左子树）或右子树（当*p是右子树）即可，作此修改也不破坏二叉排序树的特性。 若*p结点的左子树和右子树均不空。在删去*p之后，为保持其它元素之间的相对位置不变，可按中序遍历保持有序进行调整，可以有两种做法：其一是令*p的左子树为*f的左/右(依*p是*f的左子树还是右子树而定)子树，*s为*p左子树的最右下的结点，而*p的右子树为*s的右子树；其二是令*p的直接前驱（或直接后继）替代*p，然后再从二叉排序树中删去它的直接前驱（或直接后继）－即让*f的左子树(如果有的话)成为*p左子树的最左下结点(如果有的话)，再让*f成为*p的左右结点的父结点。 四、红黑树 五、完全二叉树（AVL树） 若设二叉树的高度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第h层有叶子结点，并且叶子结点都是从左到右依次排布，这就是完全二叉树 六、满二叉树 除了叶结点外每一个结点都有左右子叶且叶子结点都处在最底层的二叉树 七、B树 所有非叶子结点至多拥有两个儿子（Left和Right）； 所有结点存储一个关键字； 非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； B树的搜索，从根结点开始，如果查询的关键字与结点的关键字相等，那么就命中；否则，如果查询关键字比结点关键字小，就进入左儿子；如果比结点关键字大，就进入右儿子；如果左儿子或右儿子的指针为空，则报告找不到相应的关键字。 如果B树的所有非叶子结点的左右子树的结点数目均保持差不多（平衡），那么B树的搜索性能逼近二分查找；但它比连续内存空间的二分查找的优点是，改变B树结构（插入与删除结点）不需要移动大段的内存数据，甚至通常是常数开销。 B+树 B*树","categories":[{"name":"C语言","slug":"C语言","permalink":"http://www.lxzfranky.com/categories/C语言/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://www.lxzfranky.com/tags/二叉树/"}]},{"title":"计算机为什么使用补码进行计算","slug":"c-data-calculate","date":"2017-09-14T08:33:01.000Z","updated":"2017-09-14T08:39:59.000Z","comments":true,"path":"2017/09/14/c-data-calculate/","link":"","permalink":"http://www.lxzfranky.com/2017/09/14/c-data-calculate/","excerpt":"","text":"机器数和真值 机器数 一个数在计算机中的二进制表示形式, 叫做这个数的机器数。机器数是带符号的，在计算机用一个数的最高位存放符号, 正数为0, 负数为1. 比如，十进制中的数 +3 ，计算机字长为8位，转换成二进制就是00000011。如果是 -3 ，就是 10000011 。那么，这里的 00000011 和 10000011 就是机器数。 真值 因为第一位是符号位，所以机器数的形式值就不等于真正的数值。例如上面的有符号数 10000011，其最高位1代表负，其真正数值是 -3 而不是形式值131（10000011转换成十进制等于131）。所以，为区别起见，将带符号位的机器数对应的真正数值称为机器数的真值。 例：0000 0001的真值 = +000 0001 = +1，1000 0001的真值 = –000 0001 = –1 原码 原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是8位二进制: [+1]原 = 0000 0001 [-1]原 = 1000 0001 第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是: [1111 1111 , 0111 1111]，即： [-127 , 127] 原码是人脑最容易理解和计算的表示方式. 反码 反码的表示方法是：正数的反码是其本身；的反码是在其原码的基础上, 符号位不变，其余各个位取反。 [+1] = [00000001]原 = [00000001]反 [-1] = [10000001]原 = [11111110]反 可见如果一个反码表示的是负数, 人脑无法直观的看出来它的数值. 通常要将其转换成原码再计算。 补码 补码的表示方法是：正数的补码就是其本身；的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1) [+1] = [00000001]原 = [00000001]反 = [00000001]补 [-1] = [10000001]原 = [11111110]反 = [11111111]补 对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值. 为何要使用原码, 反码和补码 在开始深入学习前, 我的学习建议是先”死记硬背”上面的原码, 反码和补码的表示方式以及计算方法. 现在我们知道了计算机可以有三种编码方式表示一个数. 对于正数因为三种编码方式的结果都相同: [+1] = [00000001]原 = [00000001]反 = [00000001]补 所以不需要过多解释. 但是对于负数: [-1] = [10000001]原 = [11111110]反 = [11111111]补 可见原码, 反码和补码是完全不同的. 既然原码才是被人脑直接识别并用于计算表示方式, 为何还会有反码和补码呢? 首先, 因为人脑可以知道第一位是符号位, 在计算的时候我们会根据符号位, 选择对真值区域的加减. (真值的概念在本文最开头). 但是对于计算机, 加减乘数已经是最基础的运算, 要设计的尽量简单. 计算机辨别”符号位”显然会让计算机的基础电路设计变得十分复杂! 于是人们想出了将符号位也参与运算的方法. 我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0 , 所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了. 于是人们开始探索 将符号位参与运算, 并且只保留加法的方法. 首先来看原码。计算十进制的表达式: 1-1=0 1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2 如果用原码表示, 让符号位也参与计算, 显然对于减法来说, 结果是不正确的.这也就是为何计算机内部不使用原码表示一个数. 为了解决原码做减法的问题, 出现了反码。计算十进制的表达式: 1-1=0 1 - 1 = 1 + (-1)= [0000 0001]原 + [1000 0001]原= [0000 0001]反 + [1111 1110]反= [1111 1111]反 = [1000 0000]原= -0 发现用反码计算减法, 结果的真值部分是正确的. 而唯一的问题其实就出现在”0”这个特殊的数值上. 虽然人们理解上+0和-0是一样的, 但是0带符号是没有任何意义的. 而且会有[0000 0000]原和[1000 0000]原两个编码表示0. 于是补码的出现, 解决了0的符号以及两个编码的问题: 1-1 = 1 + (-1)= [0000 0001]原 + [1000 0001]原= [0000 0001]补 + [1111 1111]补= [0000 0000]补=[0000 0000]原 这样0用[0000 0000]表示, 而以前出现问题的-0则不存在了.而且可以用[1000 0000]表示-128: (-1) + (-127) = [1000 0001]原 + [1111 1111]原= [1111 1111]补 + [1000 0001]补= [1000 0000]补 -1-127的结果应该是-128, 在用补码运算的结果中, [1000 0000]补 就是-128. 但是注意因为实际上是使用以前的-0的补码来表示-128, 所以-128并没有原码和反码表示.(对-128的补码表示[1000 0000]补算出来的原码是[0000 0000]原, 这是不正确的) 使用补码, 不仅仅修复了0的符号以及存在两个编码的问题, 而且还能够多表示一个最低数. 这就是为什么8位二进制, 使用原码或反码表示的范围为[-127, +127], 而使用补码表示的范围为[-128, 127]. 因为机器使用补码, 所以对于编程中常用到的32位int类型, 可以表示范围是: [-231, 231-1] 因为第一位表示的是符号位.而使用补码表示时又可以多保存一个最小值. 补码表示的溢出问题 以下是本人的补充的理解，不知道是否正确： 由于计算机中的数字用补码表示，例如8bit的byte类型的表示范围为： [-128, 127] 0 = [0000 0000]（补） -128 = [1000 0000]（补） 127 = [0111 1111]（补） 当byte类型的变量超上限127时，如： +128 = -（-128）= 127 + 1= [1111 1111]（补）+ [0000 0001]（补）= [1000 0000]（补）= -128 +129 = 127 + 2= [1111 1111]（补）+ [0000 0001]（补）= [1000 0001]（补）= [1111 1111]（原）= -127 当byte类型的变量超过下限-128时： -129 = -128 - 1= [1000 0000]（补) - [0000 0001]（补）= [0111 1111]（补）= 127 -130 = -128 - 2= [1000 0000]（补) - [0000 0010]（补）= [0111 1110]（补）= 126","categories":[{"name":"C语言","slug":"C语言","permalink":"http://www.lxzfranky.com/categories/C语言/"}],"tags":[{"name":"补码","slug":"补码","permalink":"http://www.lxzfranky.com/tags/补码/"}]},{"title":"终端样式","slug":"env-zsh-style","date":"2017-09-12T02:01:17.000Z","updated":"2017-09-12T02:24:37.000Z","comments":true,"path":"2017/09/12/env-zsh-style/","link":"","permalink":"http://www.lxzfranky.com/2017/09/12/env-zsh-style/","excerpt":"","text":"又花时间整理了下zsh样式，添加了对hg的支持，有空可以diy更多有趣的内容 代码如下 1234567891011121314151617181920# HG info hg_prompt_info() &#123; # make sure this is a hg dir if [ -d '.hg' ]; then echo -n \"%&#123;$fg[magenta]%&#125;hg:(\" echo -n $(hg branch 2&gt;/dev/null) if [ -n \"$(hg status 2&gt;/dev/null)\" ]; then echo -n \" %&#123;$fg[magenta]%&#125;*\" else echo -n \" %&#123;$fg[magenta]%&#125;✔︎\" fi echo -n \"%&#123;$fg[magenta]%&#125;)%&#123;$reset_color%&#125;\" fi&#125;PROMPT=$'%&#123;$fg[green]%&#125;┌─◆%&#123;$fg[red]%&#125;❥❥❥%&#123;$fg[cyan]%&#125;%n%&#123;$fg[red]%&#125;@%&#123;$fg[yellow]%&#125;%M% %&#123;$fg[red]%&#125;❥❥❥ %&#123;$fg[cyan]%&#125;%~ %&#123;$fg[red]%&#125;❥❥❥ %&#123;$fg[[cyan]%&#125;'%D&#123;\"%b月%d日 星期%a %H:%M:%S\"&#125;%b$'%&#123;$fg[blue]%&#125; %&#123;$fg[red]%&#125;❥❥❥%&#123;$fg[green]%&#125;└─&gt;%&#123;$fg[red]%&#125;❥❥❥🌿 %&#123;$fg[magenta]%&#125;$(hg_prompt_info)$(git_prompt_info)$(svn_prompt_info)🌱 %&#123;$fg[red]%&#125;❥❥❥ 🌴 🌴 🌴 %&#123;$fg[magenta]%&#125;ℳ ﹏▶︎︎%&#123;$reset_color%&#125;'","categories":[{"name":"环境配置","slug":"环境配置","permalink":"http://www.lxzfranky.com/categories/环境配置/"}],"tags":[{"name":"zsh","slug":"zsh","permalink":"http://www.lxzfranky.com/tags/zsh/"},{"name":"环境","slug":"环境","permalink":"http://www.lxzfranky.com/tags/环境/"}]},{"title":"基础算法","slug":"algorithm-index","date":"2017-09-11T03:02:15.000Z","updated":"2017-09-12T09:57:01.000Z","comments":true,"path":"2017/09/11/algorithm-index/","link":"","permalink":"http://www.lxzfranky.com/2017/09/11/algorithm-index/","excerpt":"","text":"","categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://www.lxzfranky.com/categories/算法学习/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.lxzfranky.com/tags/算法/"}]},{"title":"PHP常见面试题","slug":"php-basics","date":"2017-09-07T15:06:19.000Z","updated":"2017-09-22T11:26:13.000Z","comments":true,"path":"2017/09/07/php-basics/","link":"","permalink":"http://www.lxzfranky.com/2017/09/07/php-basics/","excerpt":"","text":"问题列表 php中接口、抽象类区别 Http请求与相应 Innodb与MyISAM区别 MySQL类型float double decimal的区别 MYSQL性能优化方案 MYSQL慢查询问题 MYSQL分库，分表，主从，集群，负载均衡器 MYSQL存储结构 MYSQL双机热备和负载均衡 MYSQL索引相关知识 php中接口、抽象类区别 接口 对接口的使用是通过关键字implements 接口不能定义成员变量（包括类静态变量），能定义常量 子类必须实现接口定义的所有方法 接口只能定义不能实现该方法 接口没有构造函数 接口中的方法和实现它的类默认都是public类型的 抽象类 对抽象类的使用是通过关键字extends 不能被实例化，可以定义子类必须实现的方法 子类必须定义父类中的所有抽象方法，这些方法的访问控制必须和父类中一样（或者更为宽松） 如一个类中有一个抽象方法，则该类必须定义为抽象类 抽象类可以有构造函数 抽象类中的方法可以使用private,protected,public来修饰。 一个类可以同时实现多个接口，但一个类只能继承于一个抽象类。 Http请求与相应 HTTP请求 HTTP请求的格式如下所示： 1234&lt;request-line&gt;&lt;headers&gt;&lt;blank line&gt;[&lt;request-body&gt;] 在HTTP请求中，第一行必须是一个请求行（request line），用来说明请求类型、要访问的资源以及使用的HTTP版本。紧接着是一个首部（header）小节，用来说明服务器要使用的附加信息。在首部之后是一个空行，再此之后可以添加任意的其他数据[称之为主体（body） 在HTTP中，定义了多种请求类型，通常我们关心的只有GET请求和POST请求。只要在Web浏览器上输入一个URL，浏览器就将基于该URL向服务器发送一个GET请求，以告诉服务器获取并返回什么资源。 对于www.baidu.com的GET请求如下所示： 12345GET / HTTP/1.1Host: www.baidu.comUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6)Gecko/20050225 Firefox/1.0.1Connection: Keep-Alive 请求行的第一部分说明了该请求是GET请求。该行的第二部分是一个斜杠（/），用来说明请求的是该域名的根目录。该行的最后一部分说明使用的是HTTP 1.1版本（另一个可选项是1.0）。 第二行是请求的第一个首部，HOST。首部HOST将指出请求的目的地。结合HOST和上一行中的斜杠（/），可以通知服务器请求的是www.baidu.com/（HTTP 1.1才需要使用首部HOST，而原来的1.0版本则不需要使用）。 第三行中包含的是首部User-Agent，服务器端和客户端脚本都能够访问它，它是浏览器类型检测逻辑的重要基础。该信息由你使用的浏览器来定义（在本例中是Firefox 1.0.1），并且在每个请求中将自动发送。 最后一行是首部Connection，通常将浏览器操作设置为Keep-Alive（当然也可以设置为其他值）。注意，在最后一个首部之后有一个空行。即使不存在请求主体，这个空行也是必需的。 要发送GET请求的参数，则必须将这些额外的信息附在URL本身的后面。其格式类似于： 1URL ? name1=value1&amp;name2=value2&amp;..&amp;nameN=valueN 该信息称之为查询字符串（query string），它将会复制在HTTP请求的请求行中，如下所示： 12345GET /books/?name=Professional%20Ajax HTTP/1.1Host: www.baidu.comUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6)Gecko/20050225 Firefox/1.0.1Connection: Keep-Alive 注意，为了将文本“Professional Ajax”作为URL的参数，需要编码处理其内容，将空格替换成%20，这称为URL编码（URL encoding），常用于HTTP的许多地方（JavaScript提供了内建的函数来处理URL编码和解码）。“名称—值”（name—value）对用 &amp; 隔开。绝大部分的服务器端技术能够自动对请求主体进行解码，并为这些值的访问提供一些逻辑方式。当然，如何使用这些数据还是由服务器决定的。 另一方面，POST请求在请求主体中为服务器提供了一些附加的信息。通常，当填写一个在线表单并提交它时，这些填入的数据将以POST请求的方式发送给服务器。 以下就是一个典型的POST请求： 12345678POST / HTTP/1.1Host: www.baidu.comUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6)Gecko/20050225 Firefox/1.0.1Content-Type: application/x-www-form-urlencodedContent-Length: 40Connection: Keep-Alivename=Professional%20Ajax&amp;publisher=Wiley 从上面可以发现， POST请求和GET请求之间有一些区别。首先，请求行开始处的GET改为了POST，以表示不同的请求类型。你会发现首部Host和User-Agent仍然存在，在后面有两个新行。其中首部Content-Type说明了请求主体的内容是如何编码的。浏览器始终以application/ x-www-form- urlencoded的格式编码来传送数据，这是针对简单URL编码的MIME类型。首部Content-Length说明了请求主体的字节数。在首部Connection后是一个空行，再后面就是请求主体。与大多数浏览器的POST请求一样，这是以简单的“名称—值”对的形式给出的，其中name是Professional Ajax，publisher是Wiley。你可以以同样的格式来组织URL的查询字符串参数。 下面是一些最常见的请求头： 123456789101112131415Accept：浏览器可接受的MIME类型。Accept - Charset：浏览器可接受的字符集。Accept - Encoding：浏览器能够进行解码的数据编码方式，比如gzip。Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面。许多情形下这可以减少5到10倍的下载时间。Accept - Language：浏览器所希望的语言种类，当服务器能够提供一种以上的语言版本时要用到。Authorization：授权信息，通常出现在对服务器发送的WWW - Authenticate头的应答中。Connection：表示是否需要持久连接。如果Servlet看到这里的值为“Keep - Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点，Servlet需要在应答中发送一个Content - Length头，最简单的实现方法是：先把内容写入ByteArrayOutputStream，然后在正式写出内容之前计算它的大小。Content - Length：表示请求消息正文的长度。Cookie：这是最重要的请求头信息之一，参见后面《Cookie处理》一章中的讨论。From：请求发送者的email地址，由一些特殊的Web客户程序使用，浏览器不会用到它。Host：初始URL中的主机和端口。If - Modified - Since：只有当所请求的内容在指定的日期之后又经过修改才返回它，否则返回304“Not Modified”应答。Pragma：指定“no - cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝。Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。User - Agent：浏览器类型，如果Servlet返回的内容与浏览器类型有关则该值非常有用。UA - Pixels，UA - Color，UA - OS，UA - CPU：由某些版本的IE浏览器所发送的非标准的请求头，表示屏幕大小、颜色深度、操作系统和CPU类型。 HTTP响应 如下所示，HTTP响应的格式与请求的格式十分类似： 1234&lt;status-line&gt;&lt;headers&gt;&lt;blank line&gt;[&lt;response-body&gt;] 正如你所见，在响应中唯一真正的区别在于第一行中用状态信息代替了请求信息。状态行（status line）通过提供一个状态码来说明所请求的资源情况。 以下就是一个HTTP响应的例子： 123456789101112HTTP/1.1 200 OKDate: Sat, 31 Dec 2005 23:59:59 GMTContent-Type: text/html;charset=ISO-8859-1Content-Length: 122&lt;html&gt;&lt;head&gt;&lt;title&gt;Wrox Homepage&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- body goes here --&gt;&lt;/body&gt;&lt;/html&gt; 在本例中，状态行给出的HTTP状态代码是200，以及消息OK。状态行始终包含的是状态码和相应的简短消息，以避免混乱。最常用的状态码有： 12345200 (OK): 找到了该资源，并且一切正常。304 (NOT MODIFIED): 该资源在上次请求之后没有任何修改。这通常用于浏览器的缓存机制。401 (UNAUTHORIZED): 客户端无权访问该资源。这通常会使得浏览器要求用户输入用户名和密码，以登录到服务器。403 (FORBIDDEN): 客户端未能获得授权。这通常是在401之后输入了不正确的用户名或密码。404 (NOT FOUND): 在指定的位置不存在所申请的资源。 在状态行之后是一些首部。通常，服务器会返回一个名为Data的首部，用来说明响应生成的日期和时间（服务器通常还会返回一些关于其自身的信息，尽管并非是必需的）。 接下来的两个首部大家应该熟悉，就是与POST请求中一样的Content-Type和Content-Length。在本例中，首部Content-Type指定了MIME类型HTML（text/html），其编码类型是ISO-8859-1（这是针对美国英语资源的编码标准）。响应主体所包含的就是所请求资源的HTML源文件（尽管还可能包含纯文本或其他资源类型的二进制数据）。浏览器将把这些数据显示给用户。 注意，这里并没有指明针对该响应的请求类型，不过这对于服务器并不重要。客户端知道每种类型的请求将返回什么类型的数据，并决定如何使用这些数据。 扩展参考 HTTP请求方法对照表 HTTP响应头和请求头信息对照表 HTTP状态码对照表 Innodb与MyISAM区别 存储结构MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI(MYIndex)。InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。 存储空间MyISAM：可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。 可移植性、备份及恢复MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。 事务支持MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。 AUTO_INCREMENTMyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。 表锁差异MyISAM：只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。 全文索引MyISAM：支持 FULLTEXT类型的全文索引InnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。 表主键MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。InnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。 表的具体行数MyISAM：保存有表的总行数，如果select count(*) from table;会直接取出出该值。InnoDB：没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。 CURD操作MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。 外键MyISAM：不支持InnoDB：支持通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储 过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。 MySQL类型float double decimal的区别MySQL性能优化方案查看Mysql配置参数 12mysql&gt; show global status;mysql&gt; show variables; 慢查询 123456789101112131415mysql&gt; show variables like &apos;slow%&apos;;+------------------+-------+| variable_name | value |+------------------+-------+| log_slow_queries | on || slow_launch_time | 2 |+------------------+-------+mysql&gt; show global status like &apos;slow%&apos;;+---------------------+-------+| variable_name | value |+---------------------+-------+| slow_launch_threads | 0 || slow_queries | 4148 |+---------------------+-------+ 连接数 123456789101112mysql&gt; show variables like &apos;max_connections&apos;;+-----------------+-------+| variable_name | value |+-----------------+-------+| max_connections | 256 |+-----------------+-------+mysql&gt; show global status like &apos;max_used_connections&apos;; //服务器最大连接数mysql&gt; show global status like &apos;max_used_connections&apos;; //服务器响应的最大连接数比较理想的设置max_used_connections / max_connections * 100% ≈ 85% key_buffer_size key_buffer_size是对myisam表性能影响最大的一个参数 1234567mysql&gt; show variables like &apos;key_buffer_size&apos;;+-----------------+------------+| variable_name | value |+-----------------+------------+| key_buffer_size | 536870912 |+-----------------+------------+ 分配了512mb内存给key_buffer_size，我们再看一下key_buffer_size的使用情况： 1234567mysql&gt; show global status like &apos;key_read%&apos;;+------------------------+-------------+| variable_name | value |+------------------------+-------------+| key_read_requests | 27813678764 || key_reads | 6798830 |+------------------------+-------------+ 一共有27813678764个索引读取请求，有6798830个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率： key_cache_miss_rate ＝ key_reads / key_read_requests * 100% 比 如上面的数据，key_cache_miss_rate为0.0244%，4000个索引读取请求才有一个直接读硬盘，已经很bt 了，key_cache_miss_rate在0.1%以下都很好（每1000个请求有一个直接读硬盘），如果key_cache_miss_rate在 0.01%以下的话，key_buffer_size分配的过多，可以适当减少。 mysql服务器还提供了keyblocks*参数： 1234567mysql&gt; show global status like &apos;key_blocks_u%&apos;;+------------------------+-------------+| variable_name | value |+------------------------+-------------+| key_blocks_unused | 0 || key_blocks_used | 413543 |+------------------------+-------------+ key_blocks_unused 表示未使用的缓存簇(blocks)数，key_blocks_used表示曾经用到的最大的blocks数，比如这台服务器，所有的缓存都用到了，要么 增加key_buffer_size，要么就是过渡索引了，把缓存占满了。 12比较理想的设置：key_blocks_used / (key_blocks_unused + key_blocks_used) * 100% ≈ 80% 临时表 12345678mysql&gt; show global status like &apos;created_tmp%&apos;;+-------------------------+---------+| variable_name | value |+-------------------------+---------+| created_tmp_disk_tables | 21197 || created_tmp_files | 58 || created_tmp_tables | 1771587 |+-------------------------+---------+ 每次创建临时表，created_tmp_tables增加，如果是在磁盘上创建临时表，created_tmp_disk_tables也增加,created_tmp_files表示mysql服务创建的临时文件文件数， 12比较理想的配置是：created_tmp_disk_tables / created_tmp_tables * 100% &lt;= 25%比如上面的服务器created_tmp_disk_tables / created_tmp_tables * 100% ＝ 1.20%，应该相当好了。 我们再看一下mysql服务器对临时表的配置： 1234567mysql&gt; show variables where variable_name in (&apos;tmp_table_size&apos;, &apos;max_heap_table_size&apos;);+---------------------+-----------+| variable_name | value |+---------------------+-----------+| max_heap_table_size | 268435456 || tmp_table_size | 536870912 |+---------------------+-----------+ 只有256mb以下的临时表才能全部放内存，超过的就会用到硬盘临时表。 open table情况 1234567mysql&gt; show global status like &apos;open%tables%&apos;;+---------------+-------+| variable_name | value |+---------------+-------+| open_tables | 919 || opened_tables | 1951 |+---------------+-------+ open_tables 表示打开表的数量，opened_tables表示打开过的表数量，如果opened_tables数量过大，说明配置中 table_cache(5.1.3之后这个值叫做table_open_cache)值可能太小，我们查询一下服务器table_cache值： 123456mysql&gt; show variables like &apos;table_cache&apos;;+---------------+-------+| variable_name | value |+---------------+-------+| table_cache | 2048 |+---------------+-------+ 123比较合适的值为：open_tables / opened_tables * 100% &gt;= 85%open_tables / table_cache * 100% &lt;= 95% 进程使用情况 123456789mysql&gt; show global status like &apos;thread%&apos;;+-------------------+-------+| variable_name | value |+-------------------+-------+| threads_cached | 46 || threads_connected | 2 || threads_created | 570 || threads_running | 1 |+-------------------+-------+ 如 果我们在mysql服务器配置文件中设置了thread_cache_size，当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应下一个客户 而不是销毁（前提是缓存数未达上限）。threads_created表示创建过的线程数，如果发现threads_created值过大的话，表明 mysql服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器 thread_cache_size配置： 123456mysql&gt; show variables like &apos;thread_cache_size&apos;;+-------------------+-------+| variable_name | value |+-------------------+-------+| thread_cache_size | 64 |+-------------------+-------+ 示例中的服务器还是挺健康的。 查询缓存(query cache) 12345678910111213mysql&gt; show global status like &apos;qcache%&apos;;+-------------------------+-----------+| variable_name | value |+-------------------------+-----------+| qcache_free_blocks | 22756 || qcache_free_memory | 76764704 || qcache_hits | 213028692 || qcache_inserts | 208894227 || qcache_lowmem_prunes | 4010916 || qcache_not_cached | 13385031 || qcache_queries_in_cache | 43560 || qcache_total_blocks | 111212 |+-------------------------+-----------+ mysql查询缓存变量解释： qcache_free_blocks：缓存中相邻内存块的个数。数目大说明可能有碎片。flush query cache会对缓存中的碎片进行整理，从而得到一个空闲块。 qcache_free_memory：缓存中的空闲内存。 qcache_hits：每次查询在缓存中命中时就增大 qcache_inserts：每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。 qcache_lowmem_prunes： 缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看；如果这个数字在不断增长，就表示可能碎片非常严重，或者内存 很少。（上面的 free_blocks和free_memory可以告诉您属于哪种情况） qcache_not_cached：不适合进行缓存的查询的数量，通常是由于这些查询不是 select 语句或者用了now()之类的函数。 qcache_queries_in_cache：当前缓存的查询（和响应）的数量。 qcache_total_blocks：缓存中块的数量。 我们再查询一下服务器关于query_cache的配置： 12345678910mysql&gt; show variables like &apos;query_cache%&apos;;+------------------------------+-----------+| variable_name | value |+------------------------------+-----------+| query_cache_limit | 2097152 || query_cache_min_res_unit | 4096 || query_cache_size | 203423744 || query_cache_type | on || query_cache_wlock_invalidate | off |+------------------------------+-----------+ 各字段的解释： query_cache_limit：超过此大小的查询将不缓存 query_cache_min_res_unit：缓存块的最小大小 query_cache_size：查询缓存大小 query_cache_type：缓存类型，决定缓存什么样的查询，示例中表示不缓存 select sql_no_cache 查询 query_cache_wlock_invalidate：当有其他客户端正在对myisam表进行写操作时，如果查询在query cache中，是否返回cache结果还是等写操作完成再读表获取结果。 query_cache_min_res_unit的配置是一柄”双刃剑”，默认是4kb，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。 查询缓存碎片率 = qcache_free_blocks / qcache_total_blocks * 100% 如果查询缓存碎片率超过20%，可以用flush query cache整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。 查询缓存利用率 = (query_cache_size - qcache_free_memory) / query_cache_size * 100% 查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小；查询缓存利用率在80％以上而且qcache_lowmem_prunes &gt; 50的话说明query_cache_size可能有点小，要不就是碎片太多。 查询缓存命中率 = (qcache_hits - qcache_inserts) / qcache_hits * 100% 示例服务器 查询缓存碎片率 ＝ 20.46％，查询缓存利用率 ＝ 62.26％，查询缓存命中率 ＝ 1.94％，命中率很差，可能写操作比较频繁吧，而且可能有些碎片。 排序使用情况 123456789mysql&gt; show global status like &apos;sort%&apos;;+-------------------+------------+| variable_name | value |+-------------------+------------+| sort_merge_passes | 29 || sort_range | 37432840 || sort_rows | 9178691532 || sort_scan | 1860569 |+-------------------+------------+ sort_merge_passes 包括两步。mysql 首先会尝试在内存中做排序，使用的内存大小由系统变量 sort_buffer_size 决定，如果它的大小不够把所有的记录都读到内存中，mysql 就会把每次在内存中排序的结果存到临时文件中，等 mysql 找到所有记录之后，再把临时文件中的记录做一次排序。这再次排序就会增加 sort_merge_passes。实际上，mysql 会用另一个临时文件来存再次排序的结果，所以通常会看到 sort_merge_passes 增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增加 sort_buffer_size 会减少 sort_merge_passes 和 创建临时文件的次数。但盲目的增加 sort_buffer_size 并不一定能提高速度 文件打开数(open_files) 123456789101112131415mysql&gt; show global status like &apos;open_files&apos;;+---------------+-------+| variable_name | value |+---------------+-------+| open_files | 1410 |+---------------+-------+mysql&gt; show variables like &apos;open_files_limit&apos;;+------------------+-------+| variable_name | value |+------------------+-------+| open_files_limit | 4590 |+------------------+-------+比较合适的设置：open_files / open_files_limit * 100% &lt;= 75％ 表锁情况 1234567mysql&gt; show global status like &apos;table_locks%&apos;;+-----------------------+-----------+| variable_name | value |+-----------------------+-----------+| table_locks_immediate | 490206328 || table_locks_waited | 2084912 |+-----------------------+-----------+ table_locks_immediate表示立即释放表锁数，table_locks_waited表示需要等待的表锁数，如果 table_locks_immediate / table_locks_waited &gt; 5000，最好采用innodb引擎，因为innodb是行锁而myisam是表锁，对于高并发写入的应用innodb效果会好些。示例中的服务器 table_locks_immediate / table_locks_waited ＝ 235，myisam就足够了。 表扫描情况 1234567891011mysql&gt; show global status like &apos;handler_read%&apos;;+-----------------------+-------------+| variable_name | value |+-----------------------+-------------+| handler_read_first | 5803750 || handler_read_key | 6049319850 || handler_read_next | 94440908210 || handler_read_prev | 34822001724 || handler_read_rnd | 405482605 || handler_read_rnd_next | 18912877839 |+-----------------------+-------------+ 123456mysql&gt; show global status like &apos;com_select&apos;;+---------------+-----------+| variable_name | value |+---------------+-----------+| com_select | 222693559 |+---------------+-----------+ 计算表扫描率： 表扫描率 ＝ handler_read_rnd_next / com_select 如果表扫描率超过4000，说明进行了太多表扫描，很有可能索引没有建好，增加read_buffer_size值会有一些好处，但最好不要超过8mb。 MYSQL分库，分表，主从，集群，负载均衡器 水平切分数据库：可以降低单台机器的负载，同时最大限度的降低了宕机造成的损失 负载均衡策略：可以降低单台机器的访问负载，降低宕机的可能性 集群方案：解决了数据库宕机带来的单点数据库不能访问的问题 读写分离策略：最大限度了提高了应用中读取数据的速度和并发量 什么是数据切分Sharding 不是一个某个特定数据库软件附属的功能，而是在具体技术细节之上的抽象处理，是水平扩展(Scale Out，亦或横向扩展、向外扩展)的解决方案，其主要目的是为突破单节点数据库服务器的 I/O 能力限制，解决数据库扩展性问题。通过一系列的切分规则将数据水平分布到不同的DB或table中，在通过相应的DB路由或者table路由规则找到需要查询的具体的DB或者table，以进行Query操作。“sharding”通常是指“水平切分” 面对这样的一个表，我们怎样切分呢？怎样将这样的数据分布到不同的数据库中的表中去呢？我们可以这样做，将user_id为1～10000的所有的文章信息放入DB1中的article表中，将user_id为10001～20000的所有文章信息放入DB2中的 article表中，以此类推，一直到DBn。这样一来，文章数据就很自然的被分到了各个数据库中，达到了数据切分的目的。 接下来要解决的问题就是怎样找到具体的数据库呢？其实问题也是简单明显的，既然分库的时候我们用到了区分字段user_id，那么很自然，数据库路由的过程当然还是少不了user_id的。就是我们知道了这个blog的user_id，就利用这个user_id，利用分库时候的规则，反过来定位具体的数据库。比如user_id是234，利用刚才的规则，就应该定位到DB1，假如user_id是12343，利用该才的规则，就应该定位到DB2。以此类推，利用分库的规则，反向的路由到具体的DB，这个过程我们称之为“DB路由”。 为什么要数据切分分库降低了单点机器的负载；分表，提高了数据操作的效率 怎么做到数据切分 号段分区 （优点：可部分迁移 缺点：数据分布不均） hash取模分区 （优点：数据分布均匀 缺点：数据迁移的时候麻烦，不能按照机器性能分摊数据） 在认证库中保存数据库配置 （优点：灵活性强，一对一关系 缺点：每次查询之前都要多一次查询，性能大打折扣） 集群每一个分库的节点我们引入多台机器，每台机器保存的数据是一样的，一般情况下这多台机器分摊负载，当出现宕机情况，负载均衡器将分配负载给这台宕机的机器。例如整个数据层有Group1，Group2，Group3三个集群组成，每一个Group包括1个Master（当然Master也可以是多个）和 N个Slave，这些Master和Slave的数据是一致的。 负载均衡负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据【均匀】分摊到多个操作单元上执行，负载均衡的关键在于【均匀】。 常见互联网分布式架构如上，分为客户端层、反向代理nginx层、站点层、服务层、数据层。 常见互联网分布式架构如上，分为客户端层、反向代理nginx层、站点层、服务层、数据层。可以看到，每一个下游都有多个上游调用，只需要做到，每一个上游都均匀访问每一个下游，就能实现“将请求/数据【均匀】分摊到多个操作单元上执行”。 【客户端层-&gt;反向代理层】的负载均衡 【客户端层】到【反向代理层】的负载均衡，是通过“DNS轮询”实现的：DNS-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问DNS-server，会轮询返回这些ip，保证每个ip的解析概率是相同的。这些ip就是nginx的外网ip，以做到每台nginx的请求分配也是均衡的。 【反向代理层-&gt;站点层】的负载均衡 【反向代理层】到【站点层】的负载均衡，是通过“nginx”实现的。通过修改nginx.conf，可以实现多种负载均衡策略： 1)请求轮询：和DNS轮询类似，请求依次路由到各个web-server 2)最少连接路由：哪个web-server的连接少，路由到哪个web-server 3)ip哈希：按照访问用户的ip哈希值来路由web-server，只要用户的ip分布是均匀的，请求理论上也是均匀的，ip哈希均衡方法可以做到，同一个用户的请求固定落到同一台web-server上，此策略适合有状态服务，例如session(58沈剑备注：可以这么做，但强烈不建议这么做，站点层无状态是分布式架构设计的基本原则之一，session最好放到数据层存储) 4)… 【站点层-&gt;服务层】的负载均衡 【站点层】到【服务层】的负载均衡，是通过“服务连接池”实现的。 上游连接池会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。 上一篇文章《RPC-client实现细节》中有详细的负载均衡、故障转移、超时处理的细节描述，欢迎点击link查阅，此处不再展开。 【数据层】的负载均衡 在数据量很大的情况下，由于数据层(db，cache)涉及数据的水平切分，所以数据层的负载均衡更为复杂一些，它分为“数据的均衡”，与“请求的均衡”。 数据的均衡是指：水平切分后的每个服务(db，cache)，数据量是差不多的。 请求的均衡是指：水平切分后的每个服务(db，cache)，请求量是差不多的。 业内常见的水平切分方式有这么几种： 一、按照range水平切分 每一个数据服务，存储一定范围的数据，上图为例： user0服务，存储uid范围1-1kw user1服务，存储uid范围1kw-2kw 这个方案的好处是： (1)规则简单，service只需判断一下uid范围就能路由到对应的存储服务 (2)数据均衡性较好 (3)比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务 不足是： (1)请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大 二、按照id哈希水平切分 每一个数据服务，存储某个key值hash后的部分数据，上图为例： user0服务，存储偶数uid数据 user1服务，存储奇数uid数据 这个方案的好处是： (1)规则简单，service只需对uid进行hash能路由到对应的存储服务 (2)数据均衡性较好 (3)请求均匀性较好 不足是： (1)不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移 总结 负载均衡(Load Balance)是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据【均匀】分摊到多个操作单元上执行，负载均衡的关键在于【均匀】。 (1)【客户端层】到【反向代理层】的负载均衡，是通过“DNS轮询”实现的 (2)【反向代理层】到【站点层】的负载均衡，是通过“nginx”实现的 (3)【站点层】到【服务层】的负载均衡，是通过“服务连接池”实现的 (4)【数据层】的负载均衡，要考虑“数据的均衡”与“请求的均衡”两个点，常见的方式有“按照范围水平切分”与“hash水平切分” mysql把一个大表拆分多个表后,如何解决跨表查询效率问题 mysql对于大表(千万级),要怎么优化呢 优化sql和索引 加缓存，memcached,redis 主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具，第三方工具推荐360的atlas,其它的要么效率不高，要么没人维护 mysql自带分区表，先试试这个，对你的应用是透明的，无需更改代码,但是sql语句是需要针对分区表做优化的，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，另外分区表还有一些坑，在这里就不多说了 那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表 mysql数据库一般都是按照这个步骤去演化的，成本也是由低到高 MYSQL索引相关知识 最左前缀","categories":[{"name":"PHP学习","slug":"PHP学习","permalink":"http://www.lxzfranky.com/categories/PHP学习/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://www.lxzfranky.com/tags/面试/"}]},{"title":"hexo+github搭建免费个人博客详细教程","slug":"env-gitblog","date":"2017-09-06T05:39:39.000Z","updated":"2017-09-07T15:09:16.000Z","comments":true,"path":"2017/09/06/env-gitblog/","link":"","permalink":"http://www.lxzfranky.com/2017/09/06/env-gitblog/","excerpt":"准备工作 一个github账号 安装node.js(node官网下载)、npm(推荐brew安装) 安装git","text":"准备工作 一个github账号 安装node.js(node官网下载)、npm(推荐brew安装) 安装git 一 在GitHub创建仓库 新建一个名为你的用户名.github.io的仓库 仓库名字必须是：lxzfranky.github.io，其中lxzfranky是我的用户名 二 绑定域名（此步骤可以省略） 如果不绑定域名肯定也是可以的，就用默认的 xxx.github.io 来访问 阿里云购买域名后 执行 1ping xxx.github.com 得到对应的IP地址，去万网的控制台中解析购买的域名 在blog/public 目录下新建一个CNAME文件(无后缀名) 将自己的域名 www.lxzfranky.com填入其中 至此自己的博客基本已经完成 三 安装hexo 目前有很多工具我这里主要用的hexo其他还有Jekyll Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。 官网：http://hexo.io github: https://github.com/hexojs/hexo 安装 1$ npm install -g hexo 初始化在电脑的某个地方新建一个名为blog的文件夹（名字可以随便取），我的是~/WorkSpace/blog 在blog目录下执行 1hexo init 至此hexo安装完毕 四 本地运行 在项目根目录下执行 1hexo s # 启动服务 hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容 hexo一些常用的命令 基本命令 1234567hexo new \"postName\" #新建文章hexo new page \"pageName\" #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 缩写 1234hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 命令组合 12hexo s -g #生成并本地预览hexo d -g #生成并上传 五 配置git 编辑 根目录下的 _config.yml 文件 12345deploy: type: git repo: https://github.com/lxzfranky/lxzfranky.github.io branch: master message: 提交博客内容 安装插件 1npm install hexo-deployer-git --save 执行下面命令发布代码到博客 1hexo d 六 下载好看的主题和有用的插件 Plugins: https://hexo.io/plugins/ Themes: https://hexo.io/themes/ 主题里面自带使用教程这里就不多说了 七 其他一些设置 详见 根目录下的 _config.yml 八 开始写博客吧 到根目录下执行如下命令hexo会帮我们在_posts下生成相关md文件，打开这个文件编辑就好了 1hexo new 'my-first-blog' 完整文档格式如下 123456789---title: postName #文章页面上的显示名称，一般是中文date: 2017-09-06 13:39:39 #文章生成时间，一般不改，当然也可以任意修改categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面---以下是正文","categories":[{"name":"环境配置","slug":"环境配置","permalink":"http://www.lxzfranky.com/categories/环境配置/"}],"tags":[{"name":"环境","slug":"环境","permalink":"http://www.lxzfranky.com/tags/环境/"},{"name":"hexo","slug":"hexo","permalink":"http://www.lxzfranky.com/tags/hexo/"}]},{"title":"常用排序算法总结","slug":"algorithm-sort","date":"2017-08-26T03:20:10.000Z","updated":"2017-09-12T09:55:31.000Z","comments":true,"path":"2017/08/26/algorithm-sort/","link":"","permalink":"http://www.lxzfranky.com/2017/08/26/algorithm-sort/","excerpt":"常见排序算法总结，还有很多要完善的","text":"常见排序算法总结，还有很多要完善的 直接插入排序 原理：将数组分为无序区和有序区两个区，然后不断将无序区的第一个元素按大小顺序插入到有序区中去，最终将所有无序区元素都移动到有序区完成排序。 要点：设立哨兵，作为临时存储和判断数组边界之用。 实现： 12345678910111213141516function insertSort(&amp;$arr)&#123; $size = count($arr); for($i=1;$i&lt;$size;$i++)&#123; $tmp = $arr[$i]; $j = $i-1; while ($j&gt;-1 &amp;&amp; $tmp &lt; $arr[$i]) &#123; $arr[$j+1] = $arr[$j]; $j--; &#125; $arr[$j+1]=$tmp; &#125;&#125;$arr = array(0,4,3,5,7,2,9,1,6);insertSort($arr);print_r($arr); 希尔排序 原理：又称增量缩小排序。先将序列按增量划分为元素个数相同的若干组，使用直接插入排序法进行排序，然后不断缩小增量直至为1，最后使用直接插入排序完成排序。 要点：增量的选择以及排序最终以1为增量进行排序结束。 实现： 123function shellSort()&#123;&#125; 冒泡排序 原理：将序列划分为无序和有序区，不断通过交换较大元素至无序区尾完成排序。 要点：设计交换判断条件，提前结束以排好序的序列循环。 实现： 123456789101112131415161718function BubbleSort(&amp;$arr)&#123; $size = count($arr); for($i=0;$i&lt;$size;$i++)&#123; for($j=$i;$j&lt;$size;$j++)&#123; if($arr[$i] &gt; $arr[$j])&#123; $tmp = $arr[$j]; $arr[$j] = $arr[$i]; $arr[$i] = $tmp; &#125; &#125; &#125; return $arr;&#125;$arr = array(0,4,3,5,7,2,9,1,6);BubbleSort($arr);print_r($arr); 快速排序 原理：不断寻找一个序列的中点，然后对中点左右的序列递归的进行排序，直至全部序列排序完成，使用了分治的思想。 要点：递归、分治 实现： 12345678910111213141516171819202122232425function quickSort($arr)&#123; if(count($arr) &gt; 1)&#123; $k = $arr[0]; $x = array(); $y = array(); $size = count($arr); for($i = 1; $i &lt; $size ;$i++)&#123; if($arr[$i] &lt;= $k)&#123; $x[] = $arr[$i]; &#125;else&#123; $y[] = $arr[$i]; &#125; &#125; $x = quickSort($x); $y = quickSort($y); return array_merge($x, array($k), $y); &#125;else&#123; return $arr; &#125;&#125;$arr = array(0,4,3,5,7,2,9,1,6);$res = quickSort($arr);print_r($res);exit; 直接选择排序 原理：将序列划分为无序和有序区，寻找无序区中的最小值和无序区的首元素交换，有序区扩大一个，循环最终完成全部排序。 要点： 实现： 1234567891011121314151617181920212223function SelectSort(&amp;$arr)&#123; $length = count($arr); for($i = 0; $i &lt; $length-1; $i ++)&#123; $mink = $i; // 每次从未排序数组中找到最小值的坐标 for ($j = $i + 1; $j &lt; $length; $j++) &#123; if ($arr[$j] &lt; $arr[$mink]) &#123; $mink = $j; &#125; &#125; // 将最小值放在最前面 if ($mink != $i) &#123; $temp = $arr[$mink]; $arr[$mink] = $arr[$i]; $arr[$i] = $temp; &#125; &#125;&#125;$arr = array(0,4,3,5,7,2,9,1,6);SelectSort($arr);print_r($arr); 堆排序 原理：利用大根堆或小根堆思想，首先建立堆，然后将堆首与堆尾交换，堆尾之后为有序区。 要点：建堆、交换、调整堆 实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243//因为是数组,下标从0开始,所以,下标为n根结点的左子结点为2n+1,右子结点为2n+2; //初始化值,建立初始堆$arr=array(49,38,65,97,76,13,27,50);$arrSize=count($arr);//将第一次排序抽出来，因为最后一次排序不需要再交换值了。buildHeap($arr,$arrSize);for($i=$arrSize-1;$i&gt;0;$i--)&#123; swap($arr,$i,0); $arrSize--; buildHeap($arr,$arrSize); &#125;print_r($arr);//用数组建立最小堆function buildHeap(&amp;$arr,$arrSize)&#123; //计算出最开始的下标$index,如图,为数字\"97\"所在位置,比较每一个子树的父结点和子结点,将最小值存入父结点中 //从$index处对一个树进行循环比较,形成最小堆 for($index=intval($arrSize/2)-1; $index&gt;=0; $index--)&#123; //如果有左节点,将其下标存进最小值$min if($index*2&lt;$arrSize)&#123; $min=$index*2; //如果有右子结点,比较左右结点的大小,如果右子结点更小,将其结点的下标记录进最小值$min if($index*2+1&lt;$arrSize)&#123; if($arr[$index*2+1]&lt;$arr[$min])&#123; $min=$index*2+1; &#125; &#125; //将子结点中较小的和父结点比较,若子结点较小,与父结点交换位置,同时更新较小 if($arr[$min]&lt;$arr[$index])&#123; swap($arr,$min,$index); &#125; &#125; &#125;&#125;//此函数用来交换下数组$arr中下标为$one和$another的数据function swap(&amp;$arr,$one,$another)&#123; $tmp=$arr[$one]; $arr[$one]=$arr[$another]; $arr[$another]=$tmp;&#125; 归并排序 原理：将原序列划分为有序的两个序列，然后利用归并算法进行合并，合并之后即为有序序列。 要点：归并、分治 实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 实际实现归并排序的程序 * @param &amp;$arr array 需要排序的数组 * @param $left int 子序列的左下标值 * @param $right int 子序列的右下标值 */function mSort(&amp;$arr, $left, $right) &#123; if($left &lt; $right) &#123; //说明子序列内存在多余1个的元素，那么需要拆分，分别排序，合并 //计算拆分的位置，长度/2 去整 $center = floor(($left+$right) / 2); //递归调用对左边进行再次排序： mSort($arr, $left, $center); //递归调用对右边进行再次排序 mSort($arr, $center+1, $right); //合并排序结果 mergeArray($arr, $left, $center, $right); &#125;&#125;/** * 将两个有序数组合并成一个有序数组 * @param &amp;$arr, 待排序的所有元素 * @param $left, 排序子数组A的开始下标 * @param $center, 排序子数组A与排序子数组B的中间下标，也就是数组A的结束下标 * @param $right, 排序子数组B的结束下标（开始为$center+1) */function mergeArray(&amp;$arr, $left, $center, $right) &#123; //设置两个起始位置标记 $a_i = $left; $b_i = $center+1; while($a_i&lt;=$center &amp;&amp; $b_i&lt;=$right) &#123; //当数组A和数组B都没有越界时 if($arr[$a_i] &lt; $arr[$b_i]) &#123; $temp[] = $arr[$a_i++]; &#125; else &#123; $temp[] = $arr[$b_i++]; &#125; &#125; //判断 数组A内的元素是否都用完了，没有的话将其全部插入到C数组内： while($a_i &lt;= $center) &#123; $temp[] = $arr[$a_i++]; &#125; //判断 数组B内的元素是否都用完了，没有的话将其全部插入到C数组内： while($b_i &lt;= $right) &#123; $temp[] = $arr[$b_i++]; &#125; //将$arrC内排序好的部分，写入到$arr内： for($i=0, $len=count($temp); $i&lt;$len; $i++) &#123; $arr[$left+$i] = $temp[$i]; &#125;&#125;$arr = array(0,4,3,5,7,2,9,1,6);$len = count($arr);//求得数组长度mSort($arr, 0, $len-1);print_r($arr);exit; 基数排序 原理：将数字按位数划分出n个关键字，每次针对一个关键字进行排序，然后针对排序后的序列进行下一个关键字的排序，循环至所有关键字都使用过则排序完成。 要点：对关键字的选取，元素分配收集。 实现： 123function RadixSort()&#123;&#125;","categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://www.lxzfranky.com/categories/算法学习/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.lxzfranky.com/tags/算法/"},{"name":"排序","slug":"排序","permalink":"http://www.lxzfranky.com/tags/排序/"}]},{"title":"KMP算法学习","slug":"algorithm-kmp","date":"2017-08-02T01:20:29.000Z","updated":"2017-09-07T15:09:16.000Z","comments":true,"path":"2017/08/02/algorithm-kmp/","link":"","permalink":"http://www.lxzfranky.com/2017/08/02/algorithm-kmp/","excerpt":"","text":"","categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://www.lxzfranky.com/categories/算法学习/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://www.lxzfranky.com/tags/算法/"},{"name":"kmp","slug":"kmp","permalink":"http://www.lxzfranky.com/tags/kmp/"}]},{"title":"Laravel5.4学习笔记","slug":"php-laravel","date":"2017-08-01T08:16:23.000Z","updated":"2017-09-06T15:11:09.000Z","comments":true,"path":"2017/08/01/php-laravel/","link":"","permalink":"http://www.lxzfranky.com/2017/08/01/php-laravel/","excerpt":"最近公司开发新项目需要用Laravel框架，就学习了下做了一些笔记，方便以后回顾吧。 常用网址 API Laravel中文文档 Laravel中文社区 Laravel英文官网","text":"最近公司开发新项目需要用Laravel框架，就学习了下做了一些笔记，方便以后回顾吧。 常用网址 API Laravel中文文档 Laravel中文社区 Laravel英文官网 入门指南 通过 Laravel 安装工具 12345~/.composer/vendor/bin/composer global require \"laravel/installer\"//与直接下载远吗解压没有什么区别1. 更改权限允许web服务器写入 storage 和 bootstrap/cache2. .env.example 文件重命名为 .env3. php artisan key:generate 更新到env中 开发环境部署 本地开发服务器 12345678php artisan servephp artisan migrate:install //数据库迁移php artisan make:controller PostControllerphp artisan make:migration create_posts_talbe //创建数据迁移php artisan make:model Post //创建模型php artisan tinkerphp artisan make:auth………… 核心概念 Laravel 的请求生命周期 1. 一个 Laravel 应用的所有请求的入口都是 public/index.php 文件 2. index.php 文件载入自动加载器定义，并从 bootstrap/app.php 文件获取到 Laravel 应用实例 3. 传入的请求会被发送给 HTTP 内核或者 console 内核，ge：app/Http/Kernel.php（HTTP内核） 4. HTTP内核继承自 Illuminate\\Foundation\\Http\\Kernel 定义了一个 bootstrappers等 5. HTTP内核同时定义了一个 HTTP中间件 6. handle方法：接收一个 Request 并返回一个 Response 服务提供者 服务提供者是所有 Laravel 应用程序引导启动的中心所在。包括您自己的应用程序，以及所有的 Laravel 核心服务，都是通过服务提供者引导启动的。 所有的服务提供者都配置在config/app.php文件中的providers数组中。首先，所有提供者的register方法会被调用（只能将事务绑定到 服务容器。不应该在 register 方法中尝试注册任何事件监听器，路由或者任何其他功能。），接下来，一旦所有提供者注册完成，boot方法将会被调用。 未完待续 之前学习的笔记现在返回看的时候感觉可以精简一下，有空的时候再整理一个精简的版本。","categories":[{"name":"PHP学习","slug":"PHP学习","permalink":"http://www.lxzfranky.com/categories/PHP学习/"}],"tags":[{"name":"php","slug":"php","permalink":"http://www.lxzfranky.com/tags/php/"},{"name":"laravel","slug":"laravel","permalink":"http://www.lxzfranky.com/tags/laravel/"}]},{"title":"ASCII可显示字符","slug":"c-ascii","date":"2017-07-13T08:00:33.000Z","updated":"2017-09-13T08:21:13.000Z","comments":true,"path":"2017/07/13/c-ascii/","link":"","permalink":"http://www.lxzfranky.com/2017/07/13/c-ascii/","excerpt":"","text":"ASCII可显示字符 二进制 十进制 十六进制 图形 二进制 十进制 十六进制 图形 0010 0000 32 20 （空格）(␠) 0101 0000 80 50 P 0010 0001 33 21 ! 0101 0001 81 51 Q 0010 0010 34 22 “ 0101 0010 82 52 R 0010 0011 35 23 # 0101 0011 83 53 S 0010 0100 36 24 $ 0101 0100 84 54 T 0010 0101 37 25 % 0101 0101 85 55 U 0010 0110 38 26 &amp; 0101 0110 86 56 V 0010 0111 39 27 ‘ 0101 0111 87 57 W 0010 1000 40 28 ( 0101 1000 88 58 X 0010 1001 41 29 ) 0101 1001 89 59 Y 0010 1010 42 2A * 0101 1010 90 5A Z 0010 1011 43 2B + 0101 1011 91 5B [ 0010 1100 44 2C , 0101 1100 92 5C \\ 0010 1101 45 2D - 0101 1101 93 5D ] 0010 1110 46 2E . 0101 1110 94 5E ^ 0010 1111 47 2F / 0101 1111 95 5F _ 0011 0000 48 30 0 0110 0000 96 60 ` 0011 0001 49 31 1 0110 0001 97 61 a 0011 0010 50 32 2 0110 0010 98 62 b 0011 0011 51 33 3 0110 0011 99 63 c 0011 0100 52 34 4 0110 0100 100 64 d 0011 0101 53 35 5 0110 0101 101 65 e 0011 0110 54 36 6 0110 0110 102 66 f 0011 0111 55 37 7 0110 0111 103 67 g 0011 1000 56 38 8 0110 1000 104 68 h 0011 1001 57 39 9 0110 1001 105 69 i 0011 1010 58 3A : 0110 1010 106 6A j 0011 1011 59 3B ; 0110 1011 107 6B k 0011 1100 60 3C &lt; 0110 1100 108 6C l 0011 1101 61 3D = 0110 1101 109 6D m 0011 1110 62 3E &gt; 0110 1110 110 6E n 0011 1111 63 3F ? 0110 1111 111 6F o 0100 0000 64 40 @ 0111 0000 112 70 p 0100 0001 65 41 A 0111 0001 113 71 q 0100 0010 66 42 B 0111 0010 114 72 r 0100 0011 67 43 C 0111 0011 115 73 s 0100 0100 68 44 D 0111 0100 116 74 t 0100 0101 69 45 E 0111 0101 117 75 u 0100 0110 70 46 F 0111 0110 118 76 v 0100 0111 71 47 G 0111 0111 119 77 w 0100 1000 72 48 H 0111 1000 120 78 x 0100 1001 73 49 I 0111 1001 121 79 y 0100 1010 74 4A J 0111 1010 122 7A z 0100 1011 75 4B K 0111 1011 123 7B { 0100 1100 76 4C L 0111 1100 124 7C I 0100 1101 77 4D M 0111 1101 125 7D } 0100 1110 78 4E N 0111 1110 126 7E ~ 0100 1111 79 4F O","categories":[{"name":"C语言","slug":"C语言","permalink":"http://www.lxzfranky.com/categories/C语言/"}],"tags":[{"name":"常用查询","slug":"常用查询","permalink":"http://www.lxzfranky.com/tags/常用查询/"}]},{"title":"C语言基本数据类型简介","slug":"c-types","date":"2017-07-12T07:20:52.000Z","updated":"2017-09-13T08:21:23.000Z","comments":true,"path":"2017/07/12/c-types/","link":"","permalink":"http://www.lxzfranky.com/2017/07/12/c-types/","excerpt":"","text":"C语言基本数据类型简介 数据类型 取值范围 所占字节数 char -128 ~ +127 (1 Byte) short -32767 ~ + 32768 (2 Bytes) unsigned short 0 ~ 65536 (2 Bytes) int -2147483648 ~ 2147483647 (4 Bytes) unsigned int 0 ~ 4294967295 (4 Bytes) long -2147483648 ~ 2147483647 (4 Bytes) long long -9223372036854775808 ~ 9223372036854775807 (8 Bytes) double 1.7 * 10^308 (8 Bytes) unsigned int 0 ~ 4294967295 long -9223372036854775808 ~ 9223372036854775807 unsigned long long 0 ~ 1844674407370955161 __int64 -9223372036854775808 ~ 9223372036854775807 unsigned __int64 0 ~ 18446744073709551615 符号属性 长度属性 基本型 所占位数 取值范围 输入符举例 输出符举例 – – char 8 -2^7 ~ 2^7-1 %c %c %d %u signed – char 8 -2^7 ~ 2^7-1 %c %c %d %u unsigned – char 8 0 ~ 2^8-1 %c %c %d %u [signed] short [int] 16 -2^15 ~ 2^15-1 %hd unsigned short [int] 16 0 ~ 2^16-1 %hu %ho%hx [signed] – int 32 -2^31 ~ 2^31-1 %d unsigned – [int] 32 0 ~ 2^32-1 %u %o %x [signed] long [int] 32 -2^31 ~ 2^31-1 %ld unsigned long [int] 32 0 ~ 2^32-1 %lu %lo %lx [signed] long long [int] 64 -2^63 ~ 2^63-1 %I64d unsigned long long [int] 64 0 ~ 2^64-1 %lld %llx – – float 32 +/- 3.40282e+038 %f %e %g – – double 64 +/- 1.79769e+308 %lf %le %lg %f %e %g – long double 96 +/- 1.79769e+308 %Lf %Le %Lg 几点说明： 注意 ! 表中的每一行，代表一种基本类型。 “[]” 代表可省略。 例如： char 、 signed char 、 unsigned char 是三种互不相同的类型； int 、 short 、 long 也是三种互不相同的类型。 char/signed char/unsigned char 型数据长度为 1 字节； char 为有符号型，但与 signed char 是不同的类型。 注意 ! 并不是所有编译器都这样处理， char 型数据长度不一定为 1 字节， char 也不一定为有符号型。 将 char/signed char 转换为 int 时，会对最高符号位 1 进行扩展，从而造成运算问题。 所以 , 如果要处理的数据中存在字节值大于 127 的情况，使用 unsigned char 较为妥当。 程序中若涉及位运算，也应该使用 unsigned 型变量。 char/signed char/unsigned char 输出时，使用格式符 %c （按字符方式）； 或使用 %d 、 %u 、 %x/%X 、 %o ，按整数方式输出； 输入时，应使用 %c ，若使用整数方式， Dev-C++ 会给出警告，不建议这样使用。 int 的长度，是 16 位还是 32 位，与编译器字长有关。 16 位编译器（如 TC 使用的编译器）下， int 为 16 位； 32 位编译器（如 VC 使用的编译器 cl.exe ）下， int 为 32位。 整型数据可以使用 %d （有符号 10 进制）、 %o （无符号 8 进制）或 %x/%X （无符号 16 进制）方式输入输出。 而格式符 %u ，表示 unsigned ，即无符号 10 进制方式。 整型前缀 h 表示 short ， l 表示 long 。 输入输出 short/unsigned short 时，不建议直接使用 int 的格式符 %d/%u 等，要加前缀 h 。这个习惯性错误，来源于 TC 。 TC 下， int 的长度和默认符号属性，都与 short 一致，于是就把这两种类型当成是相同的，都用 int 方式进行输入输出。 关于 long long 类型的输入输出： “%lld” 和 “%llu” 是 linux 下 gcc/g++ 用于 long long int 类型 (64 bits) 输入输出的格式符。 而 “%I64d” 和 “%I64u” 则是 Microsoft VC++ 库里用于输入输出 __int64 类型的格式说明。 Dev-C++ 使用的编译器是 Mingw32 ， Mingw32 是 x86-win32 gcc 子项目之一，编译器核心还是 linux 下的 gcc 。 进行函数参数类型检查的是在编译阶段， gcc 编译器对格式字符串进行检查，显然它不认得 “%I64d” ， 所以将给出警告 “unknown conversion type character `I’ in format” 。对于 “%lld” 和 “%llu” ， gcc 理所当然地接受了。 Mingw32 在编译期间使用 gcc 的规则检查语法，在连接和运行时使用的却是 Microsoft 库。 这个库里的 printf 和 scanf 函数当然不认识 linux gcc 下 “%lld” 和 “%llu” ，但对 “%I64d” 和 “%I64u” ，它则是 乐意接受，并能正常工作的。 浮点型数据输入时可使用 %f 、 %e/%E 或 %g/%G ， scanf 会根据输入数据形式，自动处理。 输出时可使用 %f （普通方式）、 %e/%E （指数方式）或 %g/%G （自动选择）。 浮点参数压栈的规则： float(4 字节 ) 类型扩展成 double(8 字节 ) 入栈。所以在输入时，需要区分 float(%f) 与 double(%lf) ，而在输出时，用 %f 即可。printf 函数将按照 double 型的规则对压入堆栈的 float( 已扩展成 double) 和 double 型数据进行输出。如果在输出时指定 %lf 格式符， gcc/mingw32 编译器将给出一个警告。 Dev-C++(gcc/mingw32) 可以选择 float 的长度，是否与 double 一致。 前缀 L 表示 long （ double ）。虽然 long double 比 double 长 4 个字节，但是表示的数值范围却是一样的。long double 类型的长度、精度及表示范围与所使用的编译器、操作系统等有关。","categories":[{"name":"C语言","slug":"C语言","permalink":"http://www.lxzfranky.com/categories/C语言/"}],"tags":[{"name":"常用查询","slug":"常用查询","permalink":"http://www.lxzfranky.com/tags/常用查询/"}]}]}